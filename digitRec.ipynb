{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    from torch import nn \n",
    "    from torchvision import datasets, transforms \n",
    "\n",
    "except ImportError:\n",
    "    %pip install torch torchvision torchviz\n",
    "    import torch\n",
    "    from torch import nn \n",
    "    from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define transformation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST('data/PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\n",
    "test_set = datasets.MNIST('data/PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Layers but no Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier_NC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier_NC, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.Dropout(0,25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "classifier_NC = ImageClassifier_NC().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLassifier with 1 convolutation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier_1C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier_1C, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 26 * 26, 128),\n",
    "            nn.Dropout(0,25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "classifier_1C = ImageClassifier_1C().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLassifier with 2 convolutation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier_2C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier_2C, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 24 * 24, 128),\n",
    "            nn.Dropout(0,25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "classifier_2C = ImageClassifier_2C().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLassifier with 3 convolutation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier_3C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier_3C, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 22 * 22, 128),\n",
    "            nn.Dropout(0,25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "classifier_3C = ImageClassifier_3C().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test (model, loss_function, optimizer, train_loader, test_loader, epoch=10):\n",
    "    print(f\"Training \\\"{model.__class__.__name__}\\\": \\n\")\n",
    "    total_time = time.time()\n",
    "    for epoch in range(10):  # Train for 10 epochs\n",
    "        epoch_time = time.time()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()                   # Reset gradients\n",
    "            outputs = model(images)                 # Forward pass\n",
    "            loss = loss_function(outputs, labels)   # Compute loss\n",
    "            loss.backward()                         # Backward pass\n",
    "            optimizer.step()                        # Update weights\n",
    "\n",
    "        print(f\"Epoch:{epoch} loss is {loss.item()} in time {time.time() - epoch_time} s\")\n",
    "\n",
    "    print(f\"Total Time: {time.time() - total_time} s\")\n",
    "\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}.pt')\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for (images, labels) in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss += loss_function(outputs, labels)\n",
    "\n",
    "\n",
    "        pred = outputs.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(test_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage Val Loss: {:.4f}, Val Accuracy: {}/{} ({:.3f}%)\\n\\n\\n'.format(\n",
    "        loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training \"ImageClassifier_NC\": \n",
      "\n",
      "Epoch:0 loss is 0.37323614954948425 in time 10.333244323730469 s\n",
      "Epoch:1 loss is 0.3413008153438568 in time 9.686987400054932 s\n",
      "Epoch:2 loss is 0.19373536109924316 in time 9.72487187385559 s\n",
      "Epoch:3 loss is 0.44032177329063416 in time 9.53880786895752 s\n",
      "Epoch:4 loss is 0.3355546295642853 in time 9.600624322891235 s\n",
      "Epoch:5 loss is 0.46244385838508606 in time 10.086587190628052 s\n",
      "Epoch:6 loss is 0.5230308771133423 in time 10.000236511230469 s\n",
      "Epoch:7 loss is 0.3308674991130829 in time 9.869951725006104 s\n",
      "Epoch:8 loss is 0.2868594229221344 in time 10.101918697357178 s\n",
      "Epoch:9 loss is 0.33047857880592346 in time 9.964967012405396 s\n",
      "Total Time: 98.90920519828796 s\n",
      "\n",
      "Average Val Loss: 0.0025, Val Accuracy: 9094/10000 (90.940%)\n",
      "\n",
      "\n",
      "\n",
      "Training \"ImageClassifier_1C\": \n",
      "\n",
      "Epoch:0 loss is 0.06258121877908707 in time 9.90872836112976 s\n",
      "Epoch:1 loss is 0.06430584192276001 in time 10.147522926330566 s\n",
      "Epoch:2 loss is 0.025894837453961372 in time 10.241491556167603 s\n",
      "Epoch:3 loss is 0.03391004726290703 in time 9.688786029815674 s\n",
      "Epoch:4 loss is 0.05168106034398079 in time 9.727510929107666 s\n",
      "Epoch:5 loss is 0.0513557530939579 in time 9.77509617805481 s\n",
      "Epoch:6 loss is 0.0022626190911978483 in time 9.639047861099243 s\n",
      "Epoch:7 loss is 0.04480460286140442 in time 9.643370389938354 s\n",
      "Epoch:8 loss is 0.04337781295180321 in time 9.972138166427612 s\n",
      "Epoch:9 loss is 0.03313799947500229 in time 10.158165454864502 s\n",
      "Total Time: 98.9039957523346 s\n",
      "\n",
      "Average Val Loss: 0.0008, Val Accuracy: 9780/10000 (97.800%)\n",
      "\n",
      "\n",
      "\n",
      "Training \"ImageClassifier_2C\": \n",
      "\n",
      "Epoch:0 loss is 0.06598488241434097 in time 10.350312948226929 s\n",
      "Epoch:1 loss is 0.10242804139852524 in time 10.212002515792847 s\n",
      "Epoch:2 loss is 0.017603715881705284 in time 9.861597537994385 s\n",
      "Epoch:3 loss is 0.05693699046969414 in time 9.895218133926392 s\n",
      "Epoch:4 loss is 0.0068535697646439075 in time 9.98398208618164 s\n",
      "Epoch:5 loss is 0.009673814289271832 in time 10.04258918762207 s\n",
      "Epoch:6 loss is 0.0014661309542134404 in time 10.113832712173462 s\n",
      "Epoch:7 loss is 0.0005164544563740492 in time 10.219186782836914 s\n",
      "Epoch:8 loss is 0.0027963120955973864 in time 10.035698413848877 s\n",
      "Epoch:9 loss is 0.04505748674273491 in time 10.03067684173584 s\n",
      "Total Time: 100.74509716033936 s\n",
      "\n",
      "Average Val Loss: 0.0006, Val Accuracy: 9836/10000 (98.360%)\n",
      "\n",
      "\n",
      "\n",
      "Training \"ImageClassifier_3C\": \n",
      "\n",
      "Epoch:0 loss is 0.13179133832454681 in time 10.598818302154541 s\n",
      "Epoch:1 loss is 0.02309536188840866 in time 14.227053880691528 s\n",
      "Epoch:2 loss is 0.015258963219821453 in time 10.32958698272705 s\n",
      "Epoch:3 loss is 0.004166176076978445 in time 9.916304349899292 s\n",
      "Epoch:4 loss is 0.0007726669427938759 in time 10.023307085037231 s\n",
      "Epoch:5 loss is 0.000699260039255023 in time 9.852365255355835 s\n",
      "Epoch:6 loss is 0.010891222395002842 in time 9.863852262496948 s\n",
      "Epoch:7 loss is 0.0365455187857151 in time 9.847208738327026 s\n",
      "Epoch:8 loss is 0.010530061088502407 in time 9.986324787139893 s\n",
      "Epoch:9 loss is 0.054270628839731216 in time 9.978164672851562 s\n",
      "Total Time: 104.62415337562561 s\n",
      "\n",
      "Average Val Loss: 0.0004, Val Accuracy: 9884/10000 (98.840%)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier_NC.parameters(), lr=0.001)\n",
    "train_test(classifier_NC, loss_func, optimizer, train_loader, test_loader)\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier_1C.parameters(), lr=0.001)\n",
    "train_test(classifier_1C, loss_func, optimizer, train_loader, test_loader)\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier_2C.parameters(), lr=0.001)\n",
    "train_test(classifier_2C, loss_func, optimizer, train_loader, test_loader)\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier_3C.parameters(), lr=0.001)\n",
    "train_test(classifier_3C, loss_func, optimizer, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "__digitrec__",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
