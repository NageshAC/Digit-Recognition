{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    from torch import nn \n",
    "    from torchvision import datasets, transforms\n",
    "    # from torchview import draw_graph\n",
    "\n",
    "except ImportError:\n",
    "    !python.exe -m pip install --upgrade pip\n",
    "    %pip install torch torchvision graphviz torchview\n",
    "    import torch\n",
    "    from torch import nn \n",
    "    from torchvision import datasets, transforms\n",
    "    # from torchview import draw_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define transformation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST('data/PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\n",
    "test_set = datasets.MNIST('data/PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier with Fully Connected Layers but no Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassifier_NC(\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (2): Dropout(p=0, inplace=25)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ImageClassifier_NC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier_NC, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.Dropout(0,25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "classifier_NC = ImageClassifier_NC().to(device)\n",
    "# classifier_NC_graph = draw_graph(classifier_NC, input_size=(128, 28, 28), graph_name='classifier_NC')\n",
    "# classifier_NC_graph.visual_graph\n",
    "print(classifier_NC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier with Fully Connected Layers and 1 Convolutation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassifier_1C(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=36864, out_features=128, bias=True)\n",
      "    (2): Dropout(p=0, inplace=25)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ImageClassifier_1C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier_1C, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=5),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 24 * 24, 128),\n",
    "            nn.Dropout(0,25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "classifier_1C = ImageClassifier_1C().to(device)\n",
    "print(classifier_1C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier with Fully Connected Layers and 2 Convolutation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassifier_2C(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=25600, out_features=128, bias=True)\n",
      "    (2): Dropout(p=0, inplace=25)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ImageClassifier_2C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier_2C, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 20 * 20, 128),\n",
    "            nn.Dropout(0,25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "classifier_2C = ImageClassifier_2C().to(device)\n",
    "print(classifier_2C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLassifier with Fully Connected Layers and 3 Convolutation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassifier_3C(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=16384, out_features=128, bias=True)\n",
      "    (2): Dropout(p=0, inplace=25)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ImageClassifier_3C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier_3C, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=5),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 16 * 16, 128),\n",
    "            nn.Dropout(0,25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "classifier_3C = ImageClassifier_3C().to(device)\n",
    "print(classifier_3C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test (model, loss_function, optimizer, train_loader, test_loader, epoch=10):\n",
    "    print(f\"Training \\\"{model.__class__.__name__}\\\": \\n\")\n",
    "    total_time = time.time()\n",
    "    for epoch in range(10):  # Train for 10 epochs\n",
    "        epoch_time = time.time()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()                   # Reset gradients\n",
    "            outputs = model(images)                 # Forward pass\n",
    "            loss = loss_function(outputs, labels)   # Compute loss\n",
    "            loss.backward()                         # Backward pass\n",
    "            optimizer.step()                        # Update weights\n",
    "\n",
    "        print(f\"Epoch:{epoch} loss is {loss.item()} in time {time.time() - epoch_time} s\")\n",
    "\n",
    "    print(f\"Total Time: {time.time() - total_time} s\")\n",
    "\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}.pt')\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for (images, labels) in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss += loss_function(outputs, labels)\n",
    "\n",
    "\n",
    "        pred = outputs.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(test_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage Val Loss: {:.4f}, Val Accuracy: {}/{} ({:.3f}%)\\n\\n\\n'.format(\n",
    "        loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training \"ImageClassifier_NC\": \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 loss is 0.6718680262565613 in time 9.651752948760986 s\n",
      "Epoch:1 loss is 0.19072626531124115 in time 9.713176250457764 s\n",
      "Epoch:2 loss is 0.31419822573661804 in time 9.654514789581299 s\n",
      "Epoch:3 loss is 0.1851852387189865 in time 9.542652606964111 s\n",
      "Epoch:4 loss is 0.5819029808044434 in time 9.592023611068726 s\n",
      "Epoch:5 loss is 0.19526368379592896 in time 9.49001932144165 s\n",
      "Epoch:6 loss is 0.38364362716674805 in time 9.709181547164917 s\n",
      "Epoch:7 loss is 0.35233238339424133 in time 9.46996283531189 s\n",
      "Epoch:8 loss is 0.313971608877182 in time 9.433669567108154 s\n",
      "Epoch:9 loss is 0.42868658900260925 in time 9.481484413146973 s\n",
      "Total Time: 95.73944139480591 s\n",
      "\n",
      "Average Val Loss: 0.0024, Val Accuracy: 9114/10000 (91.140%)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(classifier_NC.parameters(), lr=0.001)\n",
    "train_test(classifier_NC, loss_func, optimizer, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training \"ImageClassifier_1C\": \n",
      "\n",
      "Epoch:0 loss is 0.0852247104048729 in time 9.702810049057007 s\n",
      "Epoch:1 loss is 0.07627455145120621 in time 9.352596998214722 s\n",
      "Epoch:2 loss is 0.0751468762755394 in time 9.330811262130737 s\n",
      "Epoch:3 loss is 0.02063712850213051 in time 9.367757797241211 s\n",
      "Epoch:4 loss is 0.03853776678442955 in time 9.386722564697266 s\n",
      "Epoch:5 loss is 0.11105111241340637 in time 9.410910367965698 s\n",
      "Epoch:6 loss is 0.02509750984609127 in time 9.420533418655396 s\n",
      "Epoch:7 loss is 0.016959430649876595 in time 9.539626598358154 s\n",
      "Epoch:8 loss is 0.0015376415103673935 in time 9.724543571472168 s\n",
      "Epoch:9 loss is 0.015790818259119987 in time 9.372647523880005 s\n",
      "Total Time: 94.61096024513245 s\n",
      "\n",
      "Average Val Loss: 0.0007, Val Accuracy: 9800/10000 (98.000%)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(classifier_1C.parameters(), lr=0.001)\n",
    "train_test(classifier_1C, loss_func, optimizer, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training \"ImageClassifier_2C\": \n",
      "\n",
      "Epoch:0 loss is 0.01912803389132023 in time 9.763724565505981 s\n",
      "Epoch:1 loss is 0.06677054613828659 in time 9.737218379974365 s\n",
      "Epoch:2 loss is 0.03951314464211464 in time 9.683794736862183 s\n",
      "Epoch:3 loss is 0.03499991074204445 in time 9.782262802124023 s\n",
      "Epoch:4 loss is 0.001068312325514853 in time 9.704952001571655 s\n",
      "Epoch:5 loss is 0.0159052275121212 in time 9.685008764266968 s\n",
      "Epoch:6 loss is 0.0020952646154910326 in time 9.676980257034302 s\n",
      "Epoch:7 loss is 0.0019339787540957332 in time 9.732737064361572 s\n",
      "Epoch:8 loss is 0.0011260228930041194 in time 9.656583547592163 s\n",
      "Epoch:9 loss is 0.0001701136789051816 in time 9.66437029838562 s\n",
      "Total Time: 97.08763241767883 s\n",
      "\n",
      "Average Val Loss: 0.0003, Val Accuracy: 9904/10000 (99.040%)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(classifier_2C.parameters(), lr=0.001)\n",
    "train_test(classifier_2C, loss_func, optimizer, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training \"ImageClassifier_3C\": \n",
      "\n",
      "Epoch:0 loss is 0.07090054452419281 in time 9.743892669677734 s\n",
      "Epoch:1 loss is 0.06147100403904915 in time 9.585543632507324 s\n",
      "Epoch:2 loss is 0.08262497186660767 in time 10.15094780921936 s\n",
      "Epoch:3 loss is 0.0025818538852036 in time 9.969598293304443 s\n",
      "Epoch:4 loss is 0.006347530987113714 in time 9.783902645111084 s\n",
      "Epoch:5 loss is 0.00021773595653939992 in time 9.744743347167969 s\n",
      "Epoch:6 loss is 0.000452357780886814 in time 9.555383443832397 s\n",
      "Epoch:7 loss is 0.0166932325810194 in time 9.543778419494629 s\n",
      "Epoch:8 loss is 0.0005363160162232816 in time 9.559114217758179 s\n",
      "Epoch:9 loss is 0.0008319418993778527 in time 9.563751220703125 s\n",
      "Total Time: 97.20065569877625 s\n",
      "\n",
      "Average Val Loss: 0.0003, Val Accuracy: 9890/10000 (98.900%)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(classifier_3C.parameters(), lr=0.001)\n",
    "train_test(classifier_3C, loss_func, optimizer, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "__digitrec__",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
